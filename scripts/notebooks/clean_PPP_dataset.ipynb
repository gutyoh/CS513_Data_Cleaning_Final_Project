{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 1.2 Python data cleaning steps\n",
    "\n",
    "In this notebook we'll perform data cleaning operations with the dataset `PPP-Data-up-to-150k-080820-HI-OpenRefineCleaned.csv` exported from `OpenRefine`.\n",
    "\n",
    "We will use libraries like `pandas` for data manipulation and `uszipcode` for properly mapping `City` column values to `Zip` code values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-07-27T21:00:26.466969400Z",
     "start_time": "2023-07-27T21:00:26.365853200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from uszipcode import SearchEngine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Load the data\n",
    "\n",
    "First, weâ€™ll load the dataset exported from OpenRefine `PPP-Data-up-to-150k-080820-HI-OpenRefineCleaned.csv` into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T21:00:26.522772700Z",
     "start_time": "2023-07-27T21:00:26.370208200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('../../data/cleaned/PPP-Data-up-to-150k-080820-HI-OpenRefineCleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 1: Remove duplicate records from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T21:00:26.525772100Z",
     "start_time": "2023-07-27T21:00:26.416576600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #1 -- Removed 17 duplicate records\n"
     ]
    }
   ],
   "source": [
    "original_length = len(df)\n",
    "df = df.drop_duplicates()\n",
    "print(f\"Step #1 -- Removed {original_length - len(df)} duplicate records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 2: Rectify `City` and `Zip` associations using the `uszipcode` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T21:00:28.629271600Z",
     "start_time": "2023-07-27T21:00:26.439874400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #2 -- Checked and rectified City and Zip associations. 1074 City names were corrected based on the Zip code value\n"
     ]
    }
   ],
   "source": [
    "search = SearchEngine()\n",
    "\n",
    "zipcode_cache = {}\n",
    "city_corrections = 0\n",
    "for i, row in df.iterrows():\n",
    "    # Using cache to avoid multiple requests for the same Zip code\n",
    "    if row[\"Zip\"] in zipcode_cache:\n",
    "        city, state = zipcode_cache[row[\"Zip\"]]\n",
    "    else:\n",
    "        # Using uszipcode library to find city and state based on Zip code\n",
    "        zipcode = search.by_zipcode(row[\"Zip\"])\n",
    "        city, state = zipcode.major_city, zipcode.state\n",
    "        zipcode_cache[row[\"Zip\"]] = (city, state)\n",
    "\n",
    "    # Check if state is not Hawaii (as it should be)\n",
    "    if state != \"HI\":\n",
    "        # Special case: One record with City=\"Honolulu\" and Zip=97817\n",
    "        # The Zip code 97817 belongs to Oregon, not Hawaii\n",
    "        # We change the Zip to 96817 (which is in Hawaii) since the City is Honolulu\n",
    "        df.at[i, \"Zip\"] = 96817\n",
    "        df.at[i, \"City\"] = \"Honolulu\"\n",
    "        df.at[i, \"State\"] = \"HI\"\n",
    "    else:\n",
    "        # If the original city name and the city name from uszipcode are not similar,\n",
    "        # overwrite the city in the dataframe with the one from uszipcode\n",
    "        original_city = df.at[i, \"City\"]\n",
    "        if original_city.lower() != city.lower():\n",
    "            city_corrections += 1\n",
    "        df.at[i, \"City\"], df.at[i, \"State\"] = city, state\n",
    "print(f\"Step #2 -- Checked and rectified City and Zip associations. {city_corrections} \"\n",
    "      f\"City names were corrected based on the Zip code value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 3: Add a new column `NAICSTitle`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T21:00:28.640075Z",
     "start_time": "2023-07-27T21:00:28.625352400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #3 -- Loaded 2678 NAICS codes and titles, and cleaned up the industry titles\n"
     ]
    }
   ],
   "source": [
    "# Load NAICS codes and titles from external file 'industry-titles.csv'\n",
    "# The file was obtained from the U.S. Bureau of Labor Statistics website\n",
    "# https://www.bls.gov/cew/classifications/industry/industry-titles.htm\n",
    "naics_df = pd.read_csv('../../data/external/industry-titles.csv')\n",
    "\n",
    "# Clean up the industry_title by removing the \"NAICS\" and the code\n",
    "naics_df['industry_title'] = naics_df['industry_title'].apply(lambda x: ' '.join(x.split(' ')[2:]))\n",
    "\n",
    "# Rename the columns to match the original dataframe\n",
    "naics_df.columns = ['NAICSCode', 'NAICSTitle']\n",
    "print(f\"Step #3 -- Loaded {len(naics_df)} NAICS codes and titles, and cleaned up the industry titles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 4: Preprocess the NAICS codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T21:00:28.711816200Z",
     "start_time": "2023-07-27T21:00:28.637427500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #4 -- Preprocessed the NAICS codes from the naics_df that holds the NAICS codes and titles. Removed 53 duplicate NAICS codes.\n"
     ]
    }
   ],
   "source": [
    "# Convert 'NAICSCode' to float while handling errors safely\n",
    "naics_df['NAICSCode'] = pd.to_numeric(naics_df['NAICSCode'], errors='coerce')\n",
    "\n",
    "# Remove rows where 'NAICSCode' is NaN\n",
    "naics_df = naics_df.dropna(subset=['NAICSCode'])\n",
    "\n",
    "# Modify 5-digit 'NAICSCode' in naics_df that have a 'NAICSCode' ending in a digit other than 0\n",
    "naics_df['NAICSCode'] = naics_df['NAICSCode'].apply(\n",
    "    lambda x: x * 10 if ((x * 10 + 1) in naics_df['NAICSCode'].values) else x)\n",
    "\n",
    "# Special case: Modify 'NAICSCode' in naics_df that have value `99999` to `999990`\n",
    "naics_df['NAICSCode'] = naics_df['NAICSCode'].apply(lambda x: x * 10 if x == 99999 else x)\n",
    "\n",
    "# Remove duplicate 'NAICSCode' in naics_df\n",
    "original_length = len(naics_df)\n",
    "naics_df.drop_duplicates(subset='NAICSCode', inplace=True)\n",
    "\n",
    "# Print number of duplicate NAICS codes removed\n",
    "print(f\"Step #4 -- Preprocessed the NAICS codes from the naics_df that holds the NAICS codes and titles. \"\n",
    "      f\"Removed {original_length - len(naics_df)} duplicate NAICS codes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 5: Merge the dataframes on `NAICSCode` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T21:00:28.711816200Z",
     "start_time": "2023-07-27T21:00:28.673811600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #5 -- Merged the dataframes on 'NAICSCode'. 21775 records were matched with a 'NAICSTitle' value.\n",
      "Handled the special case for NAICSCode `112130` and NAICSTitle `\"Dual-purpose cattle ranching and farming\"`. 7 'NAICSTitle' values were manually set.\n"
     ]
    }
   ],
   "source": [
    "# Convert 'NAICSCode' to float in both dataframes\n",
    "df['NAICSCode'] = df['NAICSCode'].astype(float)\n",
    "naics_df['NAICSCode'] = naics_df['NAICSCode'].astype(float)\n",
    "\n",
    "# Merge the original dataframe with the NAICS dataframe on 'NAICSCode'\n",
    "original_length = len(df)\n",
    "df = pd.merge(df, naics_df, on='NAICSCode', how='left')\n",
    "\n",
    "# Calculate the number of records matched with a 'NAICSTitle' value\n",
    "naicstitle_added = df['NAICSTitle'].notna().sum()\n",
    "\n",
    "# Special case: Manually set NAICSTitle \"Dual-purpose cattle ranching and farming\" to records with NAICSCode `112130`\n",
    "df.loc[df['NAICSCode'] == 112130, 'NAICSTitle'] = \"Dual-purpose cattle ranching and farming\"\n",
    "\n",
    "# Calculate the number of manually set NAICSTitles\n",
    "manual_naicstitle_count = (df['NAICSTitle'] == \"Dual-purpose cattle ranching and farming\").sum()\n",
    "print(f\"Step #5 -- Merged the dataframes on 'NAICSCode'. {naicstitle_added} \"\n",
    "      f\"records were matched with a 'NAICSTitle' value.\\n\"\n",
    "      f\"Handled the special case for NAICSCode `112130` and \"\n",
    "      f\"NAICSTitle `\\\"Dual-purpose cattle ranching and farming\\\"`. \"\n",
    "      f\"{manual_naicstitle_count} 'NAICSTitle' values were manually set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 6: Impute one missing value in `BusinessType` column with `\"Corporation\"` (the most common value in the column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-07-27T21:00:28.712817600Z",
     "start_time": "2023-07-27T21:00:28.691046500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #6 -- Imputed one (1) missing values in 'BusinessType' with 'Corporation' (the most common value)\n"
     ]
    }
   ],
   "source": [
    "df['BusinessType'] = df['BusinessType'].fillna('Corporation')\n",
    "print(\"Step #6 -- Imputed one (1) missing values in 'BusinessType' with 'Corporation' (the most common value)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Convert `NAICSCode` column values to string and save the cleaned dataframe to a new CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T21:00:28.843735200Z",
     "start_time": "2023-07-27T21:00:28.697993200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to '../../data/cleaned/PPP-Data-up-to-150k-080820-HI-OpenRefine-PythonCleaned.csv'\n"
     ]
    }
   ],
   "source": [
    "# Convert 'NAICSCode' to string after ensuring it's not a NaN value\n",
    "df.loc[~df['NAICSCode'].isna(), 'NAICSCode'] = df.loc[~df['NAICSCode'].isna(), 'NAICSCode'].astype(int).astype(str)\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "df.to_csv('../../data/cleaned/PPP-Data-up-to-150k-080820-HI-OpenRefine-PythonCleaned.csv', index=False)\n",
    "print(\"Cleaned data saved to '../../data/cleaned/PPP-Data-up-to-150k-080820-HI-OpenRefine-PythonCleaned.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
